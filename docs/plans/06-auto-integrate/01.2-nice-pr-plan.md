# PR Strategy: YouTube Transcript to XML Integration

## Executive Summary

This integration merges the experimental URL-based transcript fetcher into the main application architecture. The strategy follows TDD principles, delivers incremental value with each PR, and maintains 100% backward compatibility while enabling new functionality.

## Target Architecture

```text
models.py (shared data structures)
├── TranscriptDocument (unified container)
├── VideoMetadata (title, published, duration, url)
├── TranscriptLine (timestamp, text)
└── Chapter (title, times, transcript_lines)

Parsers (produce TranscriptDocument objects)
├── file_parser.py (refactor to use TranscriptLine objects)
└── url_parser.py (new, extracted from scripts/url_to_transcript.py)

Presentation
├── xml_builder.py (accepts TranscriptDocument)
└── cli.py (handles both file and URL workflows)
```

### Shared Models

1. **`models.py`**: Unified data structures
   ```python
   @dataclass(frozen=True)
   class VideoMetadata:
       video_title: str = ""
       video_published: str = ""  # YYYYMMDD raw format or empty
       video_duration: int = 0    # seconds (0 for file method)
       video_url: str = ""

   @dataclass(frozen=True)
   class TranscriptLine:
       timestamp: float  # seconds
       text: str

   @dataclass(frozen=True)
   class Chapter:
       title: str
       start_time: float
       end_time: float
       transcript_lines: list[TranscriptLine]

   @dataclass(frozen=True)
   class TranscriptDocument:
       metadata: VideoMetadata
       chapters: list[Chapter]
   ```

### Key Terminology

- **TranscriptLine**: A timestamp-text pair representing words spoken at a specific time (e.g., "0:02" → "Hello world")
- **Chapter**: A titled section containing multiple transcript lines (optional in YouTube videos)
- **TranscriptDocument**: Complete container with video metadata + all chapters

2. **`time_utils.py`**: All temporal utilities (already complete)
   - `timestamp_to_seconds()` - converts "M:SS" to float seconds
   - `seconds_to_timestamp()` - converts float seconds to "M:SS"
   - `format_video_published()` - converts YYYYMMDD to YYYY-MM-DD
   - `format_video_duration()` - converts seconds to "2h 15m 3s"

3. **`xml_builder.py`**: Enhanced with metadata support
   - Accepts `TranscriptDocument` objects
   - Calls `time_utils` formatting functions (separation of concerns)
   - Maintains 100% backward compatibility

## Critical Integration Challenges

### 1. Data Model Incompatibility
- **Issue**: File parser uses `transcript_lines: list[str]` (raw strings with embedded timestamps)
- **URL script uses**: `transcript_lines: list[TranscriptLine]` (structured objects)
- **Impact**: Prevents code reuse between parsers and xml_builder

### 2. Duplicate XML Generation
- **Issue**: URL script contains its own XML creation logic
- **Impact**: Violates DRY principle, maintenance burden, potential inconsistencies

### 3. Missing Shared Models
- **Issue**: Both implementations define their own incompatible `Chapter` class
- **Impact**: Cannot share xml_builder or other components

### 4. No VideoMetadata in File Workflow
- **Issue**: File parser has no concept of metadata (hardcoded empty strings in XML)
- **Impact**: Limits extensibility and consistency

## Required XML Output Format

The integration must preserve this exact XML structure for backward compatibility:

```xml
<?xml version='1.0' encoding='utf-8'?>
<transcript video_title="" video_published="" video_duration="" video_url="">
  <chapters>
    <chapter title="Introduction to Cows" start_time="0:02">
      0:02
      Welcome to this talk about erm.. er
      2:30
      Let's start with the fundamentals
    </chapter>
  </chapters>
</transcript>
```

**Note**: File method produces empty metadata attributes. URL method populates them with actual values.

## Recommended PRs in Logical Order

### PR 1: `feat/shared-models-foundation`

**PR Contents:**
- Create `src/youtube_to_xml/models.py` with shared data structures:
  - `VideoMetadata` dataclass with defaults for file workflow
  - `TranscriptLine` dataclass for structured timestamp/text pairs
  - `Chapter` dataclass using `list[TranscriptLine]` (structured objects)
  - `TranscriptDocument` container holding metadata and chapters
- Add comprehensive tests for new models in `tests/test_models.py`

**Value:** Establishes foundational data structures for entire application. No dead code - models immediately used by tests.

**Risk:** [Small] - Pure addition of new module with tests, no changes to existing functionality

**Dependencies:** None - can be merged immediately

---

### PR 2: `refactor/url-script-to-use-models`

**PR Contents:**
- Update `scripts/url_to_transcript.py` to:
  - Import shared models from `youtube_to_xml.models`
  - Remove duplicate `VideoMetadata`, `TranscriptLine`, `Chapter` definitions
  - Refactor to return `TranscriptDocument` objects
- Remove duplicate XML generation code (`create_xml_document`, `format_xml_output`)
- Use shared `xml_builder` for XML generation
- Update script tests to verify functionality preserved

**Value:** URL script now uses shared models and xml_builder. Eliminates ~100 lines of duplicate code.

**Risk:** [Small] - URL script already uses TranscriptLine objects, minimal structural changes needed

**Dependencies:** PR 1 (shared models)

---

### PR 3: `feat/enhance-xml-builder-with-transcript-document`

**PR Contents:**
- Update `xml_builder.py` to:
  - Rename function from `chapters_to_xml()` to `transcript_to_xml()` to reflect new parameter
  - Accept `TranscriptDocument` parameter: `transcript_to_xml(document)`
  - Extract metadata and chapters from document
  - Call `time_utils` formatting functions for metadata
  - Handle empty metadata gracefully (backward compatibility)
- Add tests for TranscriptDocument handling
- Add tests for metadata formatting edge cases

**Value:** XML builder now accepts unified TranscriptDocument structure, ready for both parsers.

**Risk:** [Small] - Additive change with backward compatibility

**Dependencies:** PR 1 (models), PR 2 (URL script using models)

---

### PR 4: `refactor/file-parser-to-structured-lines`

**PR Contents:**
- Update `file_parser.py` to:
  - Import `Chapter` and `TranscriptLine` from models
  - Convert string-based transcript lines to `TranscriptLine` objects during parsing
  - Parse timestamps into float seconds for TranscriptLine
  - Return `TranscriptDocument` with empty metadata and structured chapters
- Update `cli.py` to use new file parser signature
- Update all file parser tests to work with TranscriptDocument
- Ensure end-to-end tests pass with no XML output changes

**Value:** File parser now produces TranscriptDocument with structured TranscriptLine objects. Enables unified processing.

**Risk:** [Medium] - Core parser refactor from strings to objects, but comprehensive test coverage ensures safety

**Dependencies:** PRs 1-3 (needs models and updated xml_builder)

---

### PR 5: `feat/create-url-parser-module`

**PR Contents:**
- Create `src/youtube_to_xml/url_parser.py`:
  - Extract transcript fetching logic from `scripts/url_to_transcript.py`
  - Implement `fetch_transcript_document(url) -> TranscriptDocument`
  - Use shared models (already refactored in PR 2)
  - Handle all YouTube/yt-dlp exceptions with proper error mapping
- Add comprehensive tests in `tests/test_url_parser.py`
- Integration tests for various YouTube URL formats

**Value:** Creates reusable URL parser module, ready for CLI integration.

**Risk:** [Small] - Logic extraction from already-refactored script

**Dependencies:** PRs 1-4 (needs complete model infrastructure)

---

### PR 6: `feat/unified-cli-with-auto-detection`

**PR Contents:**
- Update `cli.py` to:
  - Auto-detect input type (file path vs URL)
  - Import and use `url_parser.fetch_transcript_document()` for URLs
  - Import and use enhanced `file_parser` for files
  - Both paths return `TranscriptDocument` → `xml_builder`
- Update CLI help text to show both input methods
- Add end-to-end tests for URL input via main CLI
- Update documentation with unified usage examples

**Value:** Single entry point handles both files and URLs transparently. Full integration achieved.

**Risk:** [Small] - CLI orchestration change with clear separation of concerns

**Dependencies:** PRs 1-5 (needs complete infrastructure)

---

### PR 7: `chore/cleanup-deprecated-script`

**PR Contents:**
- Delete `scripts/url_to_transcript.py` (functionality now in url_parser module)
- Update `url_to_transcript_wrapper.py` to import from new location
- Remove script entry from `pyproject.toml` if no longer needed
- Update any documentation references
- Verify all tests still pass

**Value:** Removes 400+ lines of duplicate code, single source of truth for URL processing.

**Risk:** [Small] - Deletion of deprecated code after successful integration

**Dependencies:** PR 6 (unified CLI must be working)

## Success Metrics

1. **All existing tests pass** after each PR
2. **No breaking changes** to file-based workflow
3. **Zero code duplication** between parsers
4. **Single XML generation path** for both input methods
5. **100% test coverage** for new code
6. **Identical XML output** for equivalent inputs

## PR Implementation Summary

**Foundation & Easy Refactors**
- PR 1: Shared models foundation
- PR 2: URL script refactor to models *(Easier: already uses TranscriptLine)*
- PR 3: XML builder with TranscriptDocument
- PR 4: File parser migration to structured lines: *(Harder: string→object conversion)*

**Integration & Cleanup**
- PR 5: URL parser module extraction
- PR 6: Unified CLI with auto-detection
- PR 7: Cleanup deprecated script

## Risk Mitigation

- Each PR includes comprehensive tests before implementation (TDD)
- PRs are ordered to minimize dependencies and conflicts
- Backward compatibility verified at each step
- Small, focused PRs enable quick reviews and rollbacks if needed
- Integration tests ensure end-to-end functionality preserved